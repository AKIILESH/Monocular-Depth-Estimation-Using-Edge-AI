# Monocular-Depth-Estimation-Using-Edge-AI
This project leverages deep learning to estimate pixel-wise depth maps from a single RGB image or live webcam feed in real-time. Built with modularity and efficiency in mind, it can be extended with other depth models or integrated with object detection frameworks for advanced vision applications.

# ğŸ§  Real-Time Monocular Depth Estimation

Real-time depth estimation from a single RGB image using deep learning. This project uses a pretrained monocular depth model to predict pixel-wise depth maps, allowing machines to understand the 3D structure of their environment using just one camera.

---

## ğŸ” Features

- ğŸ”µ Real-time inference using webcam or image input
- ğŸ“ Predicts per-pixel depth from a single frame
- ğŸ§  Powered by PyTorch / TensorFlow and OpenCV
- ğŸ’» Lightweight and easy to deploy
- ğŸ“· Works with live camera feeds or stored images
- ğŸ” Easily extendable to other depth models (MiDaS, Monodepth2, etc.)
- ğŸ§© Compatible with object detection models (YOLO, SSD, etc.)

> âœ… **Currently runs on a personal computer (PC)**.
> Designed for modular integration with Raspberry Pi and other Pi's.

---
ğŸ§  Tech Stack
Python 3.x
PyTorch / TensorFlow (your choice)
OpenCV
NumPy

---
ğŸ”§ Future Enhancements

âœ… Add support for object detection + depth fusion (e.g. YOLO + depth)
âœ… Integrate with MiDaS / Monodepth2 for improved accuracy
ğŸ” Optimize inference time using ONNX or TensorRT
ğŸ“± Port to edge devices (Jetson Nano, Raspberry Pi, etc.)
ğŸŒ Deploy as a web app using Flask/Streamlit
ğŸ¥ Add support for real-time depth estimation on video files
ğŸ“Š Include depth histogram and point cloud visualization
ğŸ’¬ Add voice command support for smart robotics use

---
ğŸ”Œ Uses

This project has a wide range of practical applications, including:
ğŸš— Autonomous Driving
Estimate scene depth for lane detection, obstacle avoidance, and safe navigation.
ğŸ¤– Robotics
Enable depth perception in robots using just a single camera â€” ideal for path planning and object interaction.
ğŸ› ï¸ AR/VR Development
Generate real-time depth maps for augmented reality effects and spatial interaction.
ğŸ® Gaming & Simulation
Create more immersive environments by simulating depth from 2D input.
ğŸ“· Smart Cameras & Surveillance
Improve anomaly detection and tracking with depth-aware video analysis.
ğŸ§  Computer Vision Research
Use as a base model for exploring stereo/monocular depth estimation, scene reconstruction, or 3D vision.
ğŸ“¦ Integration with Object Detection
Fuse depth and object detection models (e.g., YOLO + Depth) for smarter perception systems.

---
Comparison of other models :
![image](https://github.com/user-attachments/assets/a42879a7-d44b-4a34-822d-e278b2f0c39c)




AKILESH T
akilesht2005@gmail.com

